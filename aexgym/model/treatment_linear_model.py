import torch 
from torch import Tensor
from typing import Optional, List
from aexgym.model.base_model import BaseLinearModel

class TreatmentLinearModel(BaseLinearModel):
    """
    Assumes true reward model is r(i,a) = c_i + c_a + \epsilon where 
    c_i and c_a are an additive effects corresponding to the context index 
    arm respectively.
    """
    def __init__(self, 
                 beta_0: Tensor, 
                 sigma_0: Tensor,
                 n_arms: int,
                 s2: Tensor, 
                 use_precision: Optional[bool] = False,
                 n_objs: Optional[int] = 1,
                 standardize: Optional[bool] = True):
        
        super().__init__(beta_0, sigma_0, n_arms, s2, use_precision, n_objs, standardize) 
        
    def action_encoder(self, actions: Tensor):
        """ Takes action indices and turns them into corresponding 
        one hot vectors.
        
        """
        batch_size = len(actions)
        one_hot = torch.zeros((batch_size, self.n_arms), device=actions.device)
        one_hot[torch.arange(batch_size, device=actions.device), actions] = 1
        return one_hot

    def feature_map(self, actions, contexts, *args):
        """ 
        Creates feature vectors as follows:
        - create zero tensor with length (context_len + n_arms)
        - puts a 1 at location context and puts 1 at location context + arm
        """
        one_hot = self.action_encoder(actions)
        return torch.cat((contexts, one_hot), dim=1)
    
    def features_all_arms(self, contexts, *args):
        return super().features_all_arms(contexts)
    

    

class TreatmentPersonalModel(TreatmentLinearModel):
    """
    Assumes true reward model is r(i,a) = c_i + c_{i,a} + c_a + \epsilon where 
    c_i and c_a are an additive effects corresponding to the context index 
    arm respectively. c_{i,a} is an index and arm dependent additive effect. 
    """
    
    
    def __init__(self, 
                 beta_0: Tensor, 
                 sigma_0: Tensor,
                 n_arms: int, 
                 s2: List[float], 
                 use_precision: Optional[bool] = False,
                 n_objs: Optional[int] = 1,
                 standardize: Optional[bool] = True):
        
        super().__init__(beta_0, sigma_0, n_arms, s2, use_precision, n_objs, standardize)
        

    def feature_map(self, actions, contexts, *args):
        """
        Constructs a feature vector by creating a zero 
        tensor with length (context_len + n_arms*context_len + n_arms)

        Indices for additive context and arm effect are generated the same 
        way as the treatment effect model. Arm/context dependent effect 
        is generated by taking outerproduct of context and arm vector, then flattening.
        """
        batch_size = len(actions)
        one_hot = super().action_encoder(actions)

        #take outer product of each context and action pair and flatten 
        one_hot_mixed = torch.einsum('bc,bn->bcn', contexts, one_hot)
        one_hot_mixed = one_hot_mixed.view(batch_size, -1)
        
        return torch.cat((contexts, one_hot_mixed, one_hot), dim=1)
    
    def features_all_arms(self, contexts, *args):
        return super().features_all_arms(contexts)
    
    def reset(self):
        return super().reset()

        
    

