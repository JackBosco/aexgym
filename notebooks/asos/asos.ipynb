{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Instructions: \n",
    "\n",
    "Download the asos_digital_experiments_dataset.csv from https://osf.io/64jsb/ and put the file in data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch \n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from aexgym.model import TreatmentLinearModel, TreatmentPersonalModel\n",
    "from aexgym.agent import LinearTS, DeconfoundedTS, LinearUniform\n",
    "from aexgym.objectives import contextual_best_arm, contextual_simple_regret, constraint_best_arm\n",
    "from scripts.setup_script import make_uniform_prior\n",
    "from notebooks.asos.make_asos_env import make_matrices, ASOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "asos_path = 'data/asos_digital_experiments_dataset.csv'\n",
    "# Load the ASOS dataset\n",
    "asos_df = pd.read_csv(asos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0319, 0.0313, 0.0308, 0.0316, 0.0313, 0.0305, 0.0307, 0.0325, 0.0313,\n",
      "         0.0320],\n",
      "        [0.0156, 0.0160, 0.0163, 0.0158, 0.0160, 0.0164, 0.0163, 0.0153, 0.0160,\n",
      "         0.0156],\n",
      "        [0.0282, 0.0271, 0.0264, 0.0278, 0.0272, 0.0259, 0.0262, 0.0292, 0.0272,\n",
      "         0.0283],\n",
      "        [0.0160, 0.0150, 0.0142, 0.0156, 0.0150, 0.0137, 0.0141, 0.0171, 0.0151,\n",
      "         0.0162],\n",
      "        [0.0212, 0.0217, 0.0221, 0.0214, 0.0217, 0.0224, 0.0222, 0.0206, 0.0217,\n",
      "         0.0211],\n",
      "        [0.0071, 0.0065, 0.0060, 0.0069, 0.0065, 0.0057, 0.0060, 0.0077, 0.0065,\n",
      "         0.0072],\n",
      "        [0.0133, 0.0125, 0.0118, 0.0129, 0.0125, 0.0114, 0.0117, 0.0141, 0.0125,\n",
      "         0.0134],\n",
      "        [0.0044, 0.0046, 0.0047, 0.0045, 0.0046, 0.0048, 0.0047, 0.0042, 0.0046,\n",
      "         0.0044],\n",
      "        [0.0139, 0.0138, 0.0138, 0.0138, 0.0138, 0.0138, 0.0138, 0.0139, 0.0138,\n",
      "         0.0139],\n",
      "        [0.0165, 0.0165, 0.0164, 0.0165, 0.0165, 0.0164, 0.0164, 0.0165, 0.0165,\n",
      "         0.0165]])\n"
     ]
    }
   ],
   "source": [
    "#parameters \n",
    "n_days = 10\n",
    "n_arms = 10\n",
    "context_len = n_days \n",
    "n_steps = n_days \n",
    "batch_size = 100 \n",
    "metric_id_list = [2]\n",
    "n_objs = len(metric_id_list)\n",
    "exp_id = '036afc' \n",
    "\n",
    "\n",
    "env = ASOS(\n",
    "    asos_df = asos_df, \n",
    "    context_len = n_days, \n",
    "    batch_size = batch_size, \n",
    "    n_steps = n_steps, \n",
    "    n_arms = n_arms, \n",
    "    seed = 0, \n",
    "    exp_id = exp_id, \n",
    "    metric_id_list = metric_id_list, \n",
    "    subtract=True, \n",
    "    demean=False\n",
    ")\n",
    "\n",
    "#print means of asos env \n",
    "env.reset()\n",
    "print(env.mean_matrix[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make agent models \n",
    "s2 = torch.mean(env.var_matrix, dim=1)\n",
    "scaling = 1 / batch_size \n",
    "beta, sigma = make_uniform_prior(context_len + n_arms, scaling, n_objs)\n",
    "beta_mix, sigma_mix = make_uniform_prior(context_len + n_arms + context_len*n_arms, scaling, n_objs)\n",
    "model = TreatmentLinearModel(\n",
    "    beta_0 = beta, \n",
    "    sigma_0 = sigma, \n",
    "    n_arms = n_arms, \n",
    "    s2 = s2,\n",
    "    n_objs = n_objs\n",
    ")\n",
    "\n",
    "mix_model = TreatmentPersonalModel(\n",
    "    beta_0 = beta_mix, \n",
    "    sigma_0 = sigma_mix, \n",
    "    n_arms = n_arms, \n",
    "    s2 = s2, \n",
    "    n_objs = n_objs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent = LinearUniform(model, \"Linear Uniform\", n_samples = 10000)\n",
    "#agent = DeconfoundedTS(mix_model, \"Linear TS\", toptwo=False, n_samples = 1)\n",
    "agent = LinearTS(model, \"Linear TS\", toptwo=False, n_samples = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regret:  0.0007967464625835419\n",
      "Percent Arms Correct:  0.0\n",
      "Regret:  0.000604058023203503\n",
      "Percent Arms Correct:  0.0\n",
      "Regret:  0.0005565038216965539\n",
      "Percent Arms Correct:  0.047619047619047616\n",
      "Regret:  0.0005229148533075086\n",
      "Percent Arms Correct:  0.06451612903225806\n",
      "Regret:  0.0005339436778208105\n",
      "Percent Arms Correct:  0.04878048780487805\n",
      "Regret:  0.0005228348149388444\n",
      "Percent Arms Correct:  0.0392156862745098\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#print(env.mean_matrix)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m all_contexts, cur_step \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     14\u001b[0m beta, sigma \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#print(beta, sigma)\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/aexgym/notebooks/asos/make_asos_env.py:181\u001b[0m, in \u001b[0;36mASOS.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_matrix, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_matrix \u001b[38;5;241m=\u001b[39m make_matrices(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masos_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_arms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_counter], exp_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexp_id, metric_id_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_id_list, demean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdemean, subtract \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubtract)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m#print(self.mean_matrix)\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/repos/aexgym/notebooks/asos/make_asos_env.py:12\u001b[0m, in \u001b[0;36mmake_matrices\u001b[0;34m(asos_df, T, num_arms, arms, exp_id, metric_id_list, demean, subtract)\u001b[0m\n\u001b[1;32m     10\u001b[0m mean_matrices, var_matrices \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, metric_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(metric_id_list):\n\u001b[0;32m---> 12\u001b[0m     exp_036afc \u001b[38;5;241m=\u001b[39m asos_df[(asos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m exp_id) \u001b[38;5;241m&\u001b[39m (asos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m metric_id)]\n\u001b[1;32m     14\u001b[0m     ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(exp_036afc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_since_start\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m     arm_dat \u001b[38;5;241m=\u001b[39m {t:{k:{} \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_arms)} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ts))}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39meq)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:5803\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5800\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   5801\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 5803\u001b[0m res_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   5805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:346\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 346\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:131\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "print_probs = False\n",
    "objective = contextual_best_arm()\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "regret_list = []\n",
    "percent_arms_correct_list = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10000):\n",
    "    env.reset()\n",
    "    #print(env.mean_matrix)\n",
    "    all_contexts, cur_step = env.reset()\n",
    "    beta, sigma = agent.model.reset()\n",
    "    #print(beta, sigma)\n",
    "    beta, sigma = beta.to(device), sigma.to(device)\n",
    "    beta_0, sigma_0 = beta.clone(), sigma.clone()\n",
    "    \n",
    "    while env.n_steps - cur_step > 0:\n",
    "\n",
    "        #move to device \n",
    "        state_contexts, action_contexts, eval_contexts = tuple(contexts.to(device) for contexts in all_contexts)\n",
    "        \n",
    "        #get batch size \n",
    "        batch_size = state_contexts.shape[0]\n",
    "        #train agent \n",
    "        agent.train_agent(\n",
    "            beta = beta, \n",
    "            sigma = sigma, \n",
    "            cur_step = cur_step, \n",
    "            n_steps = env.n_steps, \n",
    "            train_context_sampler = env.sample_train_contexts, \n",
    "            eval_contexts = eval_contexts, \n",
    "            real_batch_size = batch_size, \n",
    "            objective=objective)\n",
    "        \n",
    "        #get probabilities\n",
    "        probs = agent(\n",
    "            beta = beta, \n",
    "            sigma = sigma, \n",
    "            contexts = state_contexts, \n",
    "            action_contexts = action_contexts, \n",
    "            objective = objective\n",
    "        )\n",
    "     \n",
    "        #print probabilities \n",
    "        if print_probs == True:\n",
    "            print(agent.name, env.n_steps - cur_step, torch.mean(probs, dim=0))\n",
    "        \n",
    "        #get actions and move to new state\n",
    "        actions = torch.distributions.Categorical(probs).sample()\n",
    "        \n",
    "        #move to next environment state \n",
    "        all_contexts, sampled_rewards, sampled_features, cur_step  = env.step(\n",
    "            state_contexts = state_contexts, \n",
    "            action_contexts = action_contexts, \n",
    "            actions = actions\n",
    "        )\n",
    "        \n",
    "        #update model state \n",
    "        beta, sigma = agent.model.update_posterior(\n",
    "            beta = beta_0, \n",
    "            sigma = sigma_0, \n",
    "            rewards = sampled_rewards, \n",
    "            features = agent.model.feature_map(actions, state_contexts, action_contexts), \n",
    "            idx = cur_step-1\n",
    "        )\n",
    "\n",
    "    #get evaluation contexts and true rewards \n",
    "    eval_contexts = env.sample_eval_contexts(access=True).to(device)\n",
    "    true_eval_rewards = env.get_true_rewards(eval_contexts, action_contexts)\n",
    "    \n",
    "    #calculate results from objective \n",
    "    results_dict = objective(\n",
    "        fantasy_rewards = agent.fantasize(beta, eval_contexts, action_contexts).to(device), \n",
    "        true_rewards = true_eval_rewards.to(device)\n",
    "    )\n",
    "    \n",
    "    #append results \n",
    "    percent_arms_correct_list.append(results_dict['percent_arms_correct'])\n",
    "    regret_list.append(results_dict['regret'])\n",
    "\n",
    "    #print results \n",
    "    if i % 10 == 0:\n",
    "        \n",
    "        print(\"Regret: \", np.mean(regret_list))\n",
    "        print(\"Percent Arms Correct: \", np.mean(percent_arms_correct_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwenv-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
