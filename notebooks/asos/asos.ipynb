{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Instructions: \n",
    "\n",
    "Download the asos_digital_experiments_dataset.csv from https://osf.io/64jsb/ and put the file in data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch \n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from aexgym.model import TreatmentLinearModel, TreatmentPersonalModel\n",
    "from aexgym.agent import LinearTS, DeconfoundedTS, LinearUniform\n",
    "from aexgym.objectives import contextual_best_arm, contextual_simple_regret, constraint_best_arm\n",
    "from scripts.setup_script import make_uniform_prior\n",
    "from notebooks.asos.make_asos_env import make_matrices, ASOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "asos_path = 'data/asos_digital_experiments_dataset.csv'\n",
    "# Load the ASOS dataset\n",
    "asos_df = pd.read_csv(asos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0319, 0.0313, 0.0308, 0.0316, 0.0313, 0.0305, 0.0307, 0.0325, 0.0313,\n",
      "         0.0320],\n",
      "        [0.0156, 0.0160, 0.0163, 0.0158, 0.0160, 0.0164, 0.0163, 0.0153, 0.0160,\n",
      "         0.0156],\n",
      "        [0.0282, 0.0271, 0.0264, 0.0278, 0.0272, 0.0259, 0.0262, 0.0292, 0.0272,\n",
      "         0.0283],\n",
      "        [0.0160, 0.0150, 0.0142, 0.0156, 0.0150, 0.0137, 0.0141, 0.0171, 0.0151,\n",
      "         0.0162],\n",
      "        [0.0212, 0.0217, 0.0221, 0.0214, 0.0217, 0.0224, 0.0222, 0.0206, 0.0217,\n",
      "         0.0211],\n",
      "        [0.0071, 0.0065, 0.0060, 0.0069, 0.0065, 0.0057, 0.0060, 0.0077, 0.0065,\n",
      "         0.0072],\n",
      "        [0.0133, 0.0125, 0.0118, 0.0129, 0.0125, 0.0114, 0.0117, 0.0141, 0.0125,\n",
      "         0.0134],\n",
      "        [0.0044, 0.0046, 0.0047, 0.0045, 0.0046, 0.0048, 0.0047, 0.0042, 0.0046,\n",
      "         0.0044],\n",
      "        [0.0139, 0.0138, 0.0138, 0.0138, 0.0138, 0.0138, 0.0138, 0.0139, 0.0138,\n",
      "         0.0139],\n",
      "        [0.0165, 0.0165, 0.0164, 0.0165, 0.0165, 0.0164, 0.0164, 0.0165, 0.0165,\n",
      "         0.0165]])\n"
     ]
    }
   ],
   "source": [
    "#parameters \n",
    "n_days = 10\n",
    "n_arms = 10\n",
    "context_len = n_days \n",
    "n_steps = n_days \n",
    "batch_size = 100 \n",
    "metric_id_list = [2]\n",
    "n_objs = len(metric_id_list)\n",
    "exp_id = '036afc' \n",
    "\n",
    "\n",
    "env = ASOS(\n",
    "    asos_df = asos_df, \n",
    "    context_len = n_days, \n",
    "    batch_size = batch_size, \n",
    "    n_steps = n_steps, \n",
    "    n_arms = n_arms, \n",
    "    seed = 0, \n",
    "    exp_id = exp_id, \n",
    "    metric_id_list = metric_id_list, \n",
    "    subtract=True, \n",
    "    demean=False\n",
    ")\n",
    "\n",
    "#print means of asos env \n",
    "env.reset()\n",
    "print(env.mean_matrix[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make agent models \n",
    "s2 = torch.mean(env.var_matrix, dim=1)\n",
    "scaling = 1 / batch_size \n",
    "beta, sigma = make_uniform_prior(context_len + n_arms, scaling, n_objs)\n",
    "beta_mix, sigma_mix = make_uniform_prior(context_len + n_arms + context_len*n_arms, scaling, n_objs)\n",
    "model = TreatmentLinearModel(\n",
    "    beta_0 = beta, \n",
    "    sigma_0 = sigma, \n",
    "    n_arms = n_arms, \n",
    "    s2 = s2,\n",
    "    n_objs = n_objs\n",
    ")\n",
    "\n",
    "mix_model = TreatmentPersonalModel(\n",
    "    beta_0 = beta_mix, \n",
    "    sigma_0 = sigma_mix, \n",
    "    n_arms = n_arms, \n",
    "    s2 = s2, \n",
    "    n_objs = n_objs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent = LinearUniform(model, \"Linear Uniform\", n_samples = 10000)\n",
    "#agent = DeconfoundedTS(mix_model, \"Linear TS\", toptwo=False, n_samples = 1)\n",
    "agent = LinearTS(model, \"Linear TS\", toptwo=False, n_samples = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regret:  0.0007585827261209488\n",
      "Percent Arms Correct:  0.0\n",
      "Regret:  0.00045145049013874746\n",
      "Percent Arms Correct:  0.0\n",
      "Regret:  0.000413104004803158\n",
      "Percent Arms Correct:  0.0\n",
      "Regret:  0.0004295292761056654\n",
      "Percent Arms Correct:  0.0\n",
      "Regret:  0.00046028487566040783\n",
      "Percent Arms Correct:  0.0\n",
      "Regret:  0.0004630755706160676\n",
      "Percent Arms Correct:  0.0\n",
      "Regret:  0.0004607515684405311\n",
      "Percent Arms Correct:  0.01639344262295082\n",
      "Regret:  0.00045960065974316126\n",
      "Percent Arms Correct:  0.014084507042253521\n",
      "Regret:  0.0004566308156943616\n",
      "Percent Arms Correct:  0.024691358024691357\n",
      "Regret:  0.0004395695792122202\n",
      "Percent Arms Correct:  0.054945054945054944\n",
      "Regret:  0.0004453006394133709\n",
      "Percent Arms Correct:  0.0594059405940594\n",
      "Regret:  0.000450544730500058\n",
      "Percent Arms Correct:  0.05405405405405406\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#print(env.mean_matrix)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m all_contexts, cur_step \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     13\u001b[0m beta, sigma \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#print(beta, sigma)\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/aexgym/notebooks/asos/make_asos_env.py:181\u001b[0m, in \u001b[0;36mASOS.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_matrix, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_matrix \u001b[38;5;241m=\u001b[39m make_matrices(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masos_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_arms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_counter], exp_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexp_id, metric_id_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_id_list, demean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdemean, subtract \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubtract)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m#print(self.mean_matrix)\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/repos/aexgym/notebooks/asos/make_asos_env.py:26\u001b[0m, in \u001b[0;36mmake_matrices\u001b[0;34m(asos_df, T, num_arms, arms, exp_id, metric_id_list, demean, subtract)\u001b[0m\n\u001b[1;32m     24\u001b[0m     arm_dat[t][k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariance_c\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m     arm_dat[t][k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_t\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m     arm_dat[t][k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariance_t\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1018\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1017\u001b[0m     check_dict_or_set_indexers(key)\n\u001b[0;32m-> 1018\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m:\n\u001b[1;32m   1021\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/common.py:367\u001b[0m, in \u001b[0;36mapply_if_callable\u001b[0;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# everything failed (probably because the argument\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# wasn't actually callable); we return None\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# instead of the empty string in this case to allow\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# distinguishing between no name and a name of ''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_if_callable\u001b[39m(maybe_callable, obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    368\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    Evaluate possibly callable input using obj and kwargs if it is callable,\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    otherwise return as it is.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m    **kwargs\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(maybe_callable):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "print_probs = False\n",
    "objective = contextual_best_arm()\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "regret_list = []\n",
    "percent_arms_correct_list = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10000):\n",
    "    env.reset()\n",
    "    #print(env.mean_matrix)\n",
    "    all_contexts, cur_step = env.reset()\n",
    "    beta, sigma = agent.model.reset()\n",
    "    #print(beta, sigma)\n",
    "    beta, sigma = beta.to(device), sigma.to(device)\n",
    "    beta_0, sigma_0 = beta.clone(), sigma.clone()\n",
    "    \n",
    "    while env.n_steps - cur_step > 0:\n",
    "\n",
    "        #move to device \n",
    "        state_contexts, action_contexts, eval_contexts = tuple(contexts.to(device) for contexts in all_contexts)\n",
    "        \n",
    "        #get batch size \n",
    "        batch = state_contexts.shape[0]\n",
    "        \n",
    "        #train agent \n",
    "        agent.train_agent(\n",
    "            beta, \n",
    "            sigma, \n",
    "            cur_step, \n",
    "            env.n_steps, \n",
    "            env.sample_train_contexts, \n",
    "            eval_contexts, \n",
    "            batch, \n",
    "            objective=objective)\n",
    "        #get probabilities\n",
    "        probs = agent(\n",
    "            beta = beta, \n",
    "            sigma = sigma, \n",
    "            contexts = state_contexts, \n",
    "            action_contexts = action_contexts, \n",
    "            objective = objective\n",
    "        )\n",
    "     \n",
    "        #print probabilities \n",
    "        if print_probs == True:\n",
    "            print(agent.name, env.n_steps - cur_step, torch.mean(probs, dim=0))\n",
    "        \n",
    "        #get actions and move to new state\n",
    "        actions = torch.distributions.Categorical(probs).sample()\n",
    "        \n",
    "        #move to next environment state \n",
    "        all_contexts, sampled_rewards, sampled_features, cur_step  = env.step(\n",
    "            state_contexts = state_contexts, \n",
    "            action_contexts = action_contexts, \n",
    "            actions = actions\n",
    "        )\n",
    "        \n",
    "        #update model state \n",
    "        beta, sigma = agent.model.update_posterior(\n",
    "            beta = beta_0, \n",
    "            sigma = sigma_0, \n",
    "            rewards = sampled_rewards, \n",
    "            features = agent.model.feature_map(actions, state_contexts, action_contexts), \n",
    "            idx = cur_step-1\n",
    "        )\n",
    "\n",
    "    #get evaluation contexts and true rewards \n",
    "    eval_contexts = env.sample_eval_contexts(access=True).to(device)\n",
    "    true_eval_rewards = env.get_true_rewards(eval_contexts, action_contexts)\n",
    "    \n",
    "    #calculate results from objective \n",
    "    results_dict = objective(\n",
    "        fantasy_rewards = agent.fantasize(beta, eval_contexts, action_contexts).to(device), \n",
    "        true_rewards = true_eval_rewards.to(device)\n",
    "    )\n",
    "    \n",
    "    #append results \n",
    "    percent_arms_correct_list.append(results_dict['percent_arms_correct'])\n",
    "    regret_list.append(results_dict['regret'])\n",
    "\n",
    "    #print results \n",
    "    if i % 10 == 0:\n",
    "        \n",
    "        print(\"Regret: \", np.mean(regret_list))\n",
    "        print(\"Percent Arms Correct: \", np.mean(percent_arms_correct_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwenv-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
