{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch \n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from aexgym.env import PersSyntheticEnv\n",
    "from aexgym.model import PersonalizedLinearModel\n",
    "from aexgym.agent import LinearTS, LinearUniform, LinearUCB, LinearRho\n",
    "from aexgym.objectives import contextual_best_arm, contextual_simple_regret\n",
    "from scripts.setup_script import make_uniform_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "n_days = 5\n",
    "n_arms = 10\n",
    "context_len = 5\n",
    "n_steps = n_days \n",
    "batch_size = 100\n",
    "s2 = 0.2 * torch.ones((n_days, 1))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personalization \n",
    "\n",
    "#initialize parameterss\n",
    "n_objs = 1\n",
    "scaling = 1 / (batch_size*10)\n",
    "pers_beta, pers_sigma = make_uniform_prior(context_len*n_arms, scaling, n_objs=n_objs)\n",
    "context_mu, context_var = torch.ones(context_len), 1*torch.eye(context_len)\n",
    "\n",
    "#initialize synthetic and agent model \n",
    "model = PersonalizedLinearModel(\n",
    "    beta_0 = pers_beta, \n",
    "    sigma_0 = pers_sigma, \n",
    "    n_arms = n_arms, \n",
    "    s2 = s2,  \n",
    "    n_objs=n_objs\n",
    ")\n",
    "\n",
    "#initialize synthetic environment\n",
    "env = PersSyntheticEnv(\n",
    "    model = model, \n",
    "    context_mu = context_mu, \n",
    "    context_var = context_var, \n",
    "    context_len = context_len, \n",
    "    batch_size = batch_size, \n",
    "    n_steps = n_steps\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize agent \n",
    "agent = LinearUniform(model, \"Linear Uniform\")\n",
    "agent = LinearTS(model, \"Linear TS\", toptwo=False, n_samples = 100)\n",
    "#agent = LinearTS(model, \"Linear TS\", toptwo=True, n_samples = 100)\n",
    "#agent = LinearRho(model, \"Linear Rho\", lr=0.4, weights= (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Regret:  0.060665540397167206\n",
      "Percent Arms Correct:  0.36\n",
      "10 Regret:  0.05018237927420573\n",
      "Percent Arms Correct:  0.3918181818181818\n",
      "20 Regret:  0.045457759650335425\n",
      "Percent Arms Correct:  0.40523809523809523\n",
      "30 Regret:  0.04660983699103517\n",
      "Percent Arms Correct:  0.41580645161290325\n",
      "40 Regret:  0.048848049397148735\n",
      "Percent Arms Correct:  0.40292682926829265\n",
      "50 Regret:  0.04746605415700698\n",
      "Percent Arms Correct:  0.4098039215686275\n",
      "60 Regret:  0.046968172960838335\n",
      "Percent Arms Correct:  0.41081967213114756\n",
      "70 Regret:  0.048052471603306245\n",
      "Percent Arms Correct:  0.4019718309859155\n",
      "80 Regret:  0.046316861715397714\n",
      "Percent Arms Correct:  0.4154320987654321\n",
      "90 Regret:  0.04750283258956867\n",
      "Percent Arms Correct:  0.40571428571428575\n",
      "100 Regret:  0.04676293094854544\n",
      "Percent Arms Correct:  0.40584158415841587\n",
      "110 Regret:  0.047612878082840294\n",
      "Percent Arms Correct:  0.40432432432432436\n",
      "120 Regret:  0.046184684388524244\n",
      "Percent Arms Correct:  0.41752066115702474\n",
      "130 Regret:  0.04615981278599787\n",
      "Percent Arms Correct:  0.41770992366412213\n",
      "140 Regret:  0.045902850882460676\n",
      "Percent Arms Correct:  0.42021276595744683\n",
      "150 Regret:  0.04677729620382387\n",
      "Percent Arms Correct:  0.41331125827814574\n",
      "160 Regret:  0.046568900552109715\n",
      "Percent Arms Correct:  0.41509316770186333\n",
      "170 Regret:  0.04643848105687757\n",
      "Percent Arms Correct:  0.4163742690058479\n",
      "180 Regret:  0.04665717805442478\n",
      "Percent Arms Correct:  0.4135359116022099\n",
      "190 Regret:  0.04738191059541874\n",
      "Percent Arms Correct:  0.40816753926701577\n",
      "200 Regret:  0.047435195956712785\n",
      "Percent Arms Correct:  0.4065174129353234\n",
      "210 Regret:  0.04763937100847539\n",
      "Percent Arms Correct:  0.4028436018957346\n",
      "220 Regret:  0.047001695304653895\n",
      "Percent Arms Correct:  0.40859728506787335\n",
      "230 Regret:  0.04679251143918473\n",
      "Percent Arms Correct:  0.4115151515151515\n",
      "240 Regret:  0.04729263114460833\n",
      "Percent Arms Correct:  0.40995850622406643\n",
      "250 Regret:  0.04706300762611853\n",
      "Percent Arms Correct:  0.41346613545816735\n",
      "260 Regret:  0.04670284348950361\n",
      "Percent Arms Correct:  0.4166666666666667\n",
      "270 Regret:  0.04684137876877541\n",
      "Percent Arms Correct:  0.41512915129151295\n",
      "280 Regret:  0.04697057343290264\n",
      "Percent Arms Correct:  0.41540925266903916\n",
      "290 Regret:  0.04746713588827152\n",
      "Percent Arms Correct:  0.4128178694158076\n",
      "300 Regret:  0.04740157459809931\n",
      "Percent Arms Correct:  0.4131893687707642\n",
      "310 Regret:  0.047530744404463136\n",
      "Percent Arms Correct:  0.4120900321543408\n",
      "320 Regret:  0.047872999404496124\n",
      "Percent Arms Correct:  0.41161993769470406\n",
      "330 Regret:  0.04774371117319676\n",
      "Percent Arms Correct:  0.41235649546827796\n",
      "340 Regret:  0.047760297598923585\n",
      "Percent Arms Correct:  0.41199413489736075\n",
      "350 Regret:  0.047558108193433694\n",
      "Percent Arms Correct:  0.4137606837606838\n",
      "360 Regret:  0.04752941603238315\n",
      "Percent Arms Correct:  0.41296398891966757\n",
      "370 Regret:  0.04777837646346931\n",
      "Percent Arms Correct:  0.4108086253369272\n",
      "380 Regret:  0.04787487988641334\n",
      "Percent Arms Correct:  0.40787401574803145\n",
      "390 Regret:  0.04804222542754448\n",
      "Percent Arms Correct:  0.40695652173913044\n",
      "400 Regret:  0.0478714245099788\n",
      "Percent Arms Correct:  0.40745635910224437\n",
      "410 Regret:  0.047925138338457636\n",
      "Percent Arms Correct:  0.40851581508515816\n",
      "420 Regret:  0.04776573469619003\n",
      "Percent Arms Correct:  0.40914489311163893\n",
      "430 Regret:  0.04771247509599009\n",
      "Percent Arms Correct:  0.40858468677494203\n",
      "440 Regret:  0.04778690468055321\n",
      "Percent Arms Correct:  0.408390022675737\n",
      "450 Regret:  0.04756607613970263\n",
      "Percent Arms Correct:  0.4093569844789357\n",
      "460 Regret:  0.047411420408822194\n",
      "Percent Arms Correct:  0.4101301518438178\n",
      "470 Regret:  0.047673980584822896\n",
      "Percent Arms Correct:  0.4088110403397028\n",
      "480 Regret:  0.04736869604561068\n",
      "Percent Arms Correct:  0.4114760914760915\n",
      "490 Regret:  0.04723503231497713\n",
      "Percent Arms Correct:  0.41211812627291244\n",
      "500 Regret:  0.04709165100800152\n",
      "Percent Arms Correct:  0.41375249500998\n",
      "510 Regret:  0.04693176214165854\n",
      "Percent Arms Correct:  0.4143444227005871\n",
      "520 Regret:  0.04696757222245127\n",
      "Percent Arms Correct:  0.4142226487523992\n",
      "530 Regret:  0.0467113021869921\n",
      "Percent Arms Correct:  0.41559322033898305\n",
      "540 Regret:  0.046683080313648075\n",
      "Percent Arms Correct:  0.4159889094269871\n",
      "550 Regret:  0.04650602113293271\n",
      "Percent Arms Correct:  0.41744101633393826\n",
      "560 Regret:  0.047188391611843294\n",
      "Percent Arms Correct:  0.4138146167557933\n",
      "570 Regret:  0.04733780485899196\n",
      "Percent Arms Correct:  0.41227670753064805\n",
      "580 Regret:  0.04718454841367272\n",
      "Percent Arms Correct:  0.41368330464716013\n",
      "590 Regret:  0.04727429626493789\n",
      "Percent Arms Correct:  0.41345177664974625\n",
      "600 Regret:  0.047289932546470806\n",
      "Percent Arms Correct:  0.41232945091514145\n",
      "610 Regret:  0.04738128450798228\n",
      "Percent Arms Correct:  0.4125859247135843\n",
      "620 Regret:  0.047409997467137574\n",
      "Percent Arms Correct:  0.41302737520128824\n",
      "630 Regret:  0.04744189588291048\n",
      "Percent Arms Correct:  0.4117115689381933\n",
      "640 Regret:  0.04733629838684094\n",
      "Percent Arms Correct:  0.41154446177847115\n",
      "650 Regret:  0.04727298811581644\n",
      "Percent Arms Correct:  0.41172043010752685\n",
      "660 Regret:  0.04724619276370746\n",
      "Percent Arms Correct:  0.41170953101361574\n",
      "670 Regret:  0.04740139398718289\n",
      "Percent Arms Correct:  0.41111773472429214\n",
      "680 Regret:  0.04748410440190926\n",
      "Percent Arms Correct:  0.41058737151248165\n",
      "690 Regret:  0.0472457561164814\n",
      "Percent Arms Correct:  0.41276410998552826\n",
      "700 Regret:  0.04733175518769723\n",
      "Percent Arms Correct:  0.4125677603423681\n",
      "710 Regret:  0.04753846761216469\n",
      "Percent Arms Correct:  0.4114486638537272\n",
      "720 Regret:  0.04746032571458825\n",
      "Percent Arms Correct:  0.4113592233009709\n",
      "730 Regret:  0.04777740047691663\n",
      "Percent Arms Correct:  0.40928864569083445\n",
      "740 Regret:  0.04786741092936833\n",
      "Percent Arms Correct:  0.4101214574898785\n",
      "750 Regret:  0.047995546065052644\n",
      "Percent Arms Correct:  0.40929427430093207\n",
      "760 Regret:  0.04795947780467952\n",
      "Percent Arms Correct:  0.40929040735873856\n",
      "770 Regret:  0.04813885620653861\n",
      "Percent Arms Correct:  0.408313878080415\n",
      "780 Regret:  0.04829262392702733\n",
      "Percent Arms Correct:  0.4071318822023048\n",
      "790 Regret:  0.04839643324088357\n",
      "Percent Arms Correct:  0.40788874841972184\n",
      "800 Regret:  0.048449344198206686\n",
      "Percent Arms Correct:  0.40661672908863916\n",
      "810 Regret:  0.04856536762488021\n",
      "Percent Arms Correct:  0.40556103575832303\n",
      "820 Regret:  0.048484897106005634\n",
      "Percent Arms Correct:  0.4059561510353228\n",
      "830 Regret:  0.048467942275931764\n",
      "Percent Arms Correct:  0.40551143200962697\n",
      "840 Regret:  0.04843226756998\n",
      "Percent Arms Correct:  0.40548156956004755\n",
      "850 Regret:  0.048547710016256004\n",
      "Percent Arms Correct:  0.40455934195064636\n",
      "860 Regret:  0.048531865969334884\n",
      "Percent Arms Correct:  0.40454123112659707\n",
      "870 Regret:  0.04848211708913817\n",
      "Percent Arms Correct:  0.4042824339839265\n",
      "880 Regret:  0.04859075463238457\n",
      "Percent Arms Correct:  0.4027695800227015\n",
      "890 Regret:  0.048475026585763754\n",
      "Percent Arms Correct:  0.40362514029180696\n",
      "900 Regret:  0.04840159151273119\n",
      "Percent Arms Correct:  0.40341842397336297\n",
      "910 Regret:  0.048348759579074564\n",
      "Percent Arms Correct:  0.4040724478594951\n",
      "920 Regret:  0.04825323151200039\n",
      "Percent Arms Correct:  0.404885993485342\n",
      "930 Regret:  0.04817878986607785\n",
      "Percent Arms Correct:  0.4051664876476907\n",
      "940 Regret:  0.048199312090398655\n",
      "Percent Arms Correct:  0.4047927736450584\n",
      "950 Regret:  0.04817377449308065\n",
      "Percent Arms Correct:  0.40552050473186124\n",
      "960 Regret:  0.04823070385131857\n",
      "Percent Arms Correct:  0.40492195629552546\n",
      "970 Regret:  0.04807478314252181\n",
      "Percent Arms Correct:  0.40626158599382084\n",
      "980 Regret:  0.04804756928607442\n",
      "Percent Arms Correct:  0.40627930682976554\n",
      "990 Regret:  0.047983743425169215\n",
      "Percent Arms Correct:  0.4072855701311806\n",
      "1000 Regret:  0.04801737074716971\n",
      "Percent Arms Correct:  0.4075124875124875\n",
      "1010 Regret:  0.04799483716948479\n",
      "Percent Arms Correct:  0.40785361028684475\n",
      "1020 Regret:  0.047955324058763016\n",
      "Percent Arms Correct:  0.4085014691478942\n",
      "1030 Regret:  0.04792736447709825\n",
      "Percent Arms Correct:  0.4088360814742968\n",
      "1040 Regret:  0.04795752175100412\n",
      "Percent Arms Correct:  0.4084438040345822\n",
      "1050 Regret:  0.04788637804718144\n",
      "Percent Arms Correct:  0.4085632730732635\n",
      "1060 Regret:  0.04789847352135572\n",
      "Percent Arms Correct:  0.4082563619227144\n",
      "1070 Regret:  0.04782019282476394\n",
      "Percent Arms Correct:  0.4092250233426704\n",
      "1080 Regret:  0.04773827263470274\n",
      "Percent Arms Correct:  0.40971322849213687\n",
      "1090 Regret:  0.047752354679907495\n",
      "Percent Arms Correct:  0.4093217231897342\n",
      "1100 Regret:  0.04785029472297668\n",
      "Percent Arms Correct:  0.4089009990917348\n",
      "1110 Regret:  0.04801264202472034\n",
      "Percent Arms Correct:  0.4078037803780378\n",
      "1120 Regret:  0.04788213948587107\n",
      "Percent Arms Correct:  0.4089562890276539\n",
      "1130 Regret:  0.04786354781373031\n",
      "Percent Arms Correct:  0.40821396993810793\n",
      "1140 Regret:  0.04785115163002774\n",
      "Percent Arms Correct:  0.40836108676599475\n",
      "1150 Regret:  0.04776308635333885\n",
      "Percent Arms Correct:  0.4094787141615986\n",
      "1160 Regret:  0.04777808946378458\n",
      "Percent Arms Correct:  0.4091472868217055\n",
      "1170 Regret:  0.047790299380082\n",
      "Percent Arms Correct:  0.40957301451750644\n",
      "1180 Regret:  0.04772162616251322\n",
      "Percent Arms Correct:  0.40942421676545304\n",
      "1190 Regret:  0.047730126701636316\n",
      "Percent Arms Correct:  0.4094290512174643\n",
      "1200 Regret:  0.04766701072490123\n",
      "Percent Arms Correct:  0.4097502081598668\n",
      "1210 Regret:  0.04765242826951857\n",
      "Percent Arms Correct:  0.40976878612716766\n",
      "1220 Regret:  0.04761348909108818\n",
      "Percent Arms Correct:  0.4101719901719902\n",
      "1230 Regret:  0.04757339791239676\n",
      "Percent Arms Correct:  0.410268074735987\n",
      "1240 Regret:  0.047704020619023166\n",
      "Percent Arms Correct:  0.4093795326349718\n",
      "1250 Regret:  0.04760994359241913\n",
      "Percent Arms Correct:  0.4098241406874501\n",
      "1260 Regret:  0.04758133676418596\n",
      "Percent Arms Correct:  0.4096431403647898\n",
      "1270 Regret:  0.04759520473820396\n",
      "Percent Arms Correct:  0.40955153422501966\n",
      "1280 Regret:  0.04758883398542418\n",
      "Percent Arms Correct:  0.4098360655737705\n",
      "1290 Regret:  0.04751847907475187\n",
      "Percent Arms Correct:  0.41045701006971336\n",
      "1300 Regret:  0.04746787608003417\n",
      "Percent Arms Correct:  0.41086087624903916\n",
      "1310 Regret:  0.047448240270629286\n",
      "Percent Arms Correct:  0.4106864988558353\n",
      "1320 Regret:  0.04747334840114565\n",
      "Percent Arms Correct:  0.4104769114307343\n",
      "1330 Regret:  0.047321303473305515\n",
      "Percent Arms Correct:  0.411397445529677\n",
      "1340 Regret:  0.047340583059336715\n",
      "Percent Arms Correct:  0.4113870246085012\n",
      "1350 Regret:  0.047262046844950105\n",
      "Percent Arms Correct:  0.41175425610658767\n",
      "1360 Regret:  0.04734793870109712\n",
      "Percent Arms Correct:  0.41104335047759005\n",
      "1370 Regret:  0.04748245274626333\n",
      "Percent Arms Correct:  0.4098541210795041\n",
      "1380 Regret:  0.04743361616558426\n",
      "Percent Arms Correct:  0.40982621288921073\n",
      "1390 Regret:  0.047378557662718604\n",
      "Percent Arms Correct:  0.41005751258087714\n",
      "1400 Regret:  0.04737350184534896\n",
      "Percent Arms Correct:  0.4102212705210564\n",
      "1410 Regret:  0.04733653459186427\n",
      "Percent Arms Correct:  0.41049610205528\n",
      "1420 Regret:  0.04732312646990722\n",
      "Percent Arms Correct:  0.41045038705137227\n",
      "1430 Regret:  0.04734334219159242\n",
      "Percent Arms Correct:  0.4105031446540881\n",
      "1440 Regret:  0.04736225531594201\n",
      "Percent Arms Correct:  0.41022206800832756\n",
      "1450 Regret:  0.0473189432217934\n",
      "Percent Arms Correct:  0.410434183321847\n",
      "1460 Regret:  0.04744939133859559\n",
      "Percent Arms Correct:  0.41013689253935665\n",
      "1470 Regret:  0.04740158434502051\n",
      "Percent Arms Correct:  0.4101631543167913\n",
      "1480 Regret:  0.04739498052476282\n",
      "Percent Arms Correct:  0.410371370695476\n",
      "1490 Regret:  0.04734506423861203\n",
      "Percent Arms Correct:  0.4110865191146882\n",
      "1500 Regret:  0.04735480781832584\n",
      "Percent Arms Correct:  0.41099267155229846\n",
      "1510 Regret:  0.047460163519258566\n",
      "Percent Arms Correct:  0.4103507610853739\n",
      "1520 Regret:  0.04748984980935759\n",
      "Percent Arms Correct:  0.41027613412228797\n",
      "1530 Regret:  0.047395203794382515\n",
      "Percent Arms Correct:  0.4110254735467015\n",
      "1540 Regret:  0.04735247680895021\n",
      "Percent Arms Correct:  0.41138870863075927\n",
      "1550 Regret:  0.04741631313839592\n",
      "Percent Arms Correct:  0.41056092843326886\n",
      "1560 Regret:  0.047404178200602234\n",
      "Percent Arms Correct:  0.4108648302370276\n",
      "1570 Regret:  0.04748391416495907\n",
      "Percent Arms Correct:  0.4102418841502228\n",
      "1580 Regret:  0.047464217648533355\n",
      "Percent Arms Correct:  0.41039848197343454\n",
      "1590 Regret:  0.04740373671097572\n",
      "Percent Arms Correct:  0.41102451288497804\n",
      "1600 Regret:  0.04739036600234605\n",
      "Percent Arms Correct:  0.41108682073703934\n",
      "1610 Regret:  0.04740877123708559\n",
      "Percent Arms Correct:  0.4107697082557418\n",
      "1620 Regret:  0.047453553876181734\n",
      "Percent Arms Correct:  0.4105058605798889\n",
      "1630 Regret:  0.04747321536969496\n",
      "Percent Arms Correct:  0.40985898221949724\n",
      "1640 Regret:  0.04743868383518798\n",
      "Percent Arms Correct:  0.4100792199878123\n",
      "1650 Regret:  0.047507212241899466\n",
      "Percent Arms Correct:  0.4093943064809207\n",
      "1660 Regret:  0.04749922815293706\n",
      "Percent Arms Correct:  0.40934978928356414\n",
      "1670 Regret:  0.047449370835702095\n",
      "Percent Arms Correct:  0.4093177737881508\n",
      "1680 Regret:  0.04746291242888367\n",
      "Percent Arms Correct:  0.4090838786436645\n",
      "1690 Regret:  0.04744696448665026\n",
      "Percent Arms Correct:  0.40938497930218803\n",
      "1700 Regret:  0.04744476251299222\n",
      "Percent Arms Correct:  0.4092827748383304\n",
      "1710 Regret:  0.047464515865671006\n",
      "Percent Arms Correct:  0.40922267679719465\n",
      "1720 Regret:  0.04743571300749526\n",
      "Percent Arms Correct:  0.4095700174317257\n",
      "1730 Regret:  0.047423204118848615\n",
      "Percent Arms Correct:  0.4098671288272675\n",
      "1740 Regret:  0.04736352943422648\n",
      "Percent Arms Correct:  0.41014359563469266\n",
      "1750 Regret:  0.04745073921897096\n",
      "Percent Arms Correct:  0.40932038834951456\n",
      "1760 Regret:  0.04742861769695209\n",
      "Percent Arms Correct:  0.40946053378762065\n",
      "1770 Regret:  0.04740053588718508\n",
      "Percent Arms Correct:  0.4098136645962733\n",
      "1780 Regret:  0.047444029941664384\n",
      "Percent Arms Correct:  0.4092869174621\n",
      "1790 Regret:  0.04740704077068198\n",
      "Percent Arms Correct:  0.40945281965382463\n",
      "1800 Regret:  0.047470292744450665\n",
      "Percent Arms Correct:  0.40884508606329817\n",
      "1810 Regret:  0.047438213796483907\n",
      "Percent Arms Correct:  0.4091606847045831\n",
      "1820 Regret:  0.047424786414092895\n",
      "Percent Arms Correct:  0.40942339373970343\n",
      "1830 Regret:  0.047412973115371224\n",
      "Percent Arms Correct:  0.4097760786455489\n",
      "1840 Regret:  0.047381408300249755\n",
      "Percent Arms Correct:  0.41037479630635526\n",
      "1850 Regret:  0.047335194795242015\n",
      "Percent Arms Correct:  0.4108914100486224\n",
      "1860 Regret:  0.04731143062195126\n",
      "Percent Arms Correct:  0.4107200429876411\n",
      "1870 Regret:  0.04725726024632978\n",
      "Percent Arms Correct:  0.4110636023516836\n",
      "1880 Regret:  0.04715924477439863\n",
      "Percent Arms Correct:  0.4119776714513557\n",
      "1890 Regret:  0.04712327513787137\n",
      "Percent Arms Correct:  0.4122210470650449\n",
      "1900 Regret:  0.04710936760943851\n",
      "Percent Arms Correct:  0.41251446607048925\n",
      "1910 Regret:  0.047076593514669286\n",
      "Percent Arms Correct:  0.41290947148090007\n",
      "1920 Regret:  0.04706773710149141\n",
      "Percent Arms Correct:  0.41297761582509107\n",
      "1930 Regret:  0.04701168817643545\n",
      "Percent Arms Correct:  0.4134438114966339\n",
      "1940 Regret:  0.04693688771789169\n",
      "Percent Arms Correct:  0.4140597630087584\n",
      "1950 Regret:  0.04694604270553063\n",
      "Percent Arms Correct:  0.4138851870835469\n",
      "1960 Regret:  0.04692359920816704\n",
      "Percent Arms Correct:  0.4140948495665477\n",
      "1970 Regret:  0.046879049440522645\n",
      "Percent Arms Correct:  0.41434804667681385\n",
      "1980 Regret:  0.04688280144180296\n",
      "Percent Arms Correct:  0.41425542655224634\n",
      "1990 Regret:  0.0468495924137804\n",
      "Percent Arms Correct:  0.41449522852837767\n",
      "2000 Regret:  0.04679733228768273\n",
      "Percent Arms Correct:  0.4147826086956522\n",
      "2010 Regret:  0.0467628455325574\n",
      "Percent Arms Correct:  0.4147090999502735\n",
      "2020 Regret:  0.046877336430624646\n",
      "Percent Arms Correct:  0.41441860465116276\n",
      "2030 Regret:  0.04688583281850016\n",
      "Percent Arms Correct:  0.4142589857213195\n",
      "2040 Regret:  0.04686269705436598\n",
      "Percent Arms Correct:  0.4141793238608525\n",
      "2050 Regret:  0.04689560537607927\n",
      "Percent Arms Correct:  0.4137445148707947\n",
      "2060 Regret:  0.046836192627342066\n",
      "Percent Arms Correct:  0.41407569141193595\n",
      "2070 Regret:  0.04684262838246565\n",
      "Percent Arms Correct:  0.4139159826170932\n",
      "2080 Regret:  0.04684868671932221\n",
      "Percent Arms Correct:  0.4138779432964921\n",
      "2090 Regret:  0.0468744476628011\n",
      "Percent Arms Correct:  0.41357245337159254\n",
      "2100 Regret:  0.04686020991653257\n",
      "Percent Arms Correct:  0.4135649690623513\n",
      "2110 Regret:  0.04689740011486618\n",
      "Percent Arms Correct:  0.4135480814779725\n",
      "2120 Regret:  0.04694210330539421\n",
      "Percent Arms Correct:  0.413055162659123\n",
      "2130 Regret:  0.046884868280343266\n",
      "Percent Arms Correct:  0.4135194744251525\n",
      "2140 Regret:  0.046914305890610616\n",
      "Percent Arms Correct:  0.413619803829986\n",
      "2150 Regret:  0.046945991454280564\n",
      "Percent Arms Correct:  0.4136680613668061\n",
      "2160 Regret:  0.04696899921222159\n",
      "Percent Arms Correct:  0.4134613604812587\n",
      "2170 Regret:  0.047052753124345745\n",
      "Percent Arms Correct:  0.41319668355596495\n",
      "2180 Regret:  0.047054181607006265\n",
      "Percent Arms Correct:  0.4132416322787712\n",
      "2190 Regret:  0.04703115957699009\n",
      "Percent Arms Correct:  0.41344135098128704\n",
      "2200 Regret:  0.04705168673443248\n",
      "Percent Arms Correct:  0.4132712403452976\n",
      "2210 Regret:  0.04700695827094925\n",
      "Percent Arms Correct:  0.4135413839891452\n",
      "2220 Regret:  0.04694014270886366\n",
      "Percent Arms Correct:  0.4140027014858172\n",
      "2230 Regret:  0.04689548230552165\n",
      "Percent Arms Correct:  0.4143388614970865\n",
      "2240 Regret:  0.04685934125246303\n",
      "Percent Arms Correct:  0.4144265952699688\n",
      "2250 Regret:  0.046917932337979106\n",
      "Percent Arms Correct:  0.41390493114171484\n",
      "2260 Regret:  0.04697513118810945\n",
      "Percent Arms Correct:  0.4133259619637329\n",
      "2270 Regret:  0.047017240389022615\n",
      "Percent Arms Correct:  0.413258476442096\n",
      "2280 Regret:  0.04700626200728497\n",
      "Percent Arms Correct:  0.41348969750109604\n",
      "2290 Regret:  0.0469999958230333\n",
      "Percent Arms Correct:  0.41329113924050637\n",
      "2300 Regret:  0.0469748286834138\n",
      "Percent Arms Correct:  0.4134550195567145\n",
      "2310 Regret:  0.04694567491080368\n",
      "Percent Arms Correct:  0.41375594980527913\n",
      "2320 Regret:  0.04698198688022298\n",
      "Percent Arms Correct:  0.4137139164153382\n",
      "2330 Regret:  0.04699487904043159\n",
      "Percent Arms Correct:  0.4135649935649936\n",
      "2340 Regret:  0.04701380831044643\n",
      "Percent Arms Correct:  0.41363519863306275\n",
      "2350 Regret:  0.04696234974779208\n",
      "Percent Arms Correct:  0.4141471714164186\n",
      "2360 Regret:  0.046963622575911364\n",
      "Percent Arms Correct:  0.4144980940279543\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 40\u001b[0m\n\u001b[1;32m     26\u001b[0m agent\u001b[38;5;241m.\u001b[39mtrain_agent( \n\u001b[1;32m     27\u001b[0m     beta \u001b[38;5;241m=\u001b[39m beta, \n\u001b[1;32m     28\u001b[0m     sigma \u001b[38;5;241m=\u001b[39m sigma, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m     38\u001b[0m )    \n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#get probabilities\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstate_contexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43maction_contexts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maction_contexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#print probabilities \u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m print_probs \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/o3d/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/o3d/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/aexgym/aexgym/agent/linear/linear_ts.py:44\u001b[0m, in \u001b[0;36mLinearTS.forward\u001b[0;34m(self, beta, sigma, contexts, action_contexts, objective, costs)\u001b[0m\n\u001b[1;32m     42\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch_size(contexts)\n\u001b[1;32m     43\u001b[0m n_objs \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 44\u001b[0m betas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_betas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_objs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     45\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfeatures_all_arms(contexts, action_contexts)\n\u001b[1;32m     47\u001b[0m fake_rewards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_rewards(betas, features, objective, costs)\n",
      "File \u001b[0;32m~/aexgym/aexgym/agent/linear/linear_ts.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch_size(contexts)\n\u001b[1;32m     43\u001b[0m n_objs \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 44\u001b[0m betas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_betas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_objs)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     45\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfeatures_all_arms(contexts, action_contexts)\n\u001b[1;32m     47\u001b[0m fake_rewards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_rewards(betas, features, objective, costs)\n",
      "File \u001b[0;32m~/aexgym/aexgym/agent/linear/linear_ts.py:30\u001b[0m, in \u001b[0;36mLinearTS.sample_betas\u001b[0;34m(self, beta, sigma, batch_size, n_samples)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_precision:\n\u001b[1;32m     29\u001b[0m     mvn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mMultivariateNormal(beta, precision_matrix \u001b[38;5;241m=\u001b[39m sigma)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmvn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/o3d/lib/python3.11/site-packages/torch/distributions/distribution.py:164\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mGenerates a sample_shape shaped sample or sample_shape shaped batch of\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03msamples if the distribution parameters are batched.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/o3d/lib/python3.11/site-packages/torch/distributions/multivariate_normal.py:242\u001b[0m, in \u001b[0;36mMultivariateNormal.rsample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    240\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended_shape(sample_shape)\n\u001b[1;32m    241\u001b[0m eps \u001b[38;5;241m=\u001b[39m _standard_normal(shape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m+\u001b[39m \u001b[43m_batch_mv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unbroadcasted_scale_tril\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/o3d/lib/python3.11/site-packages/torch/distributions/multivariate_normal.py:22\u001b[0m, in \u001b[0;36m_batch_mv\u001b[0;34m(bmat, bvec)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_batch_mv\u001b[39m(bmat, bvec):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    Performs a batched matrix-vector product, with compatible but different batch shapes.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    just ones which can be broadcasted.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbvec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_probs = False\n",
    "torch.manual_seed(0)\n",
    "objective = contextual_simple_regret()\n",
    "objective.weights = (0, 1)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "regret_list = []\n",
    "percent_arms_correct_list = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10000):\n",
    "    env.reset()\n",
    "    #print(env.mean_matrix)\n",
    "    cumul_regret = 0\n",
    "    all_contexts, cur_step = env.reset()\n",
    "    beta, sigma = agent.model.reset()\n",
    "    #print(beta, sigma)\n",
    "    beta, sigma = beta.to(device), sigma.to(device)\n",
    "    \n",
    "    while env.n_steps - cur_step > 0:\n",
    "\n",
    "        #move to device \n",
    "        state_contexts, action_contexts, eval_contexts = tuple(contexts.to(device) for contexts in all_contexts)\n",
    "        \n",
    "        #train agent \n",
    "        agent.train_agent( \n",
    "            beta = beta, \n",
    "            sigma = sigma, \n",
    "            cur_step = cur_step, \n",
    "            n_steps = n_steps, \n",
    "            train_context_sampler = env.sample_train_contexts, \n",
    "            eval_contexts = eval_contexts,\n",
    "            eval_action_contexts = action_contexts, \n",
    "            real_batch = batch_size, \n",
    "            print_losses=False, \n",
    "            objective=objective,\n",
    "            repeats=10000\n",
    "        )    \n",
    "        #get probabilities\n",
    "        probs = agent(\n",
    "            beta = beta, \n",
    "            sigma = sigma, \n",
    "            contexts = state_contexts, \n",
    "            action_contexts = action_contexts, \n",
    "            objective = objective\n",
    "        )\n",
    "     \n",
    "        #print probabilities \n",
    "        if print_probs == True:\n",
    "            print(agent.name, env.n_steps - cur_step, probs)\n",
    "        \n",
    "        #get actions and move to new state\n",
    "        actions = torch.distributions.Categorical(probs).sample()\n",
    "        \n",
    "        #move to next environment state \n",
    "        all_contexts, sampled_rewards, sampled_features, cur_step  = env.step(\n",
    "            state_contexts = state_contexts, \n",
    "            action_contexts = action_contexts, \n",
    "            actions = actions\n",
    "        )\n",
    "\n",
    "        rewards = objective(\n",
    "            agent_actions = actions,\n",
    "            true_rewards = env.get_true_rewards(state_contexts, action_contexts)\n",
    "        )\n",
    "\n",
    "        cumul_regret += rewards['regret']\n",
    "        \n",
    "        #update model state \n",
    "        beta, sigma = agent.model.update_posterior(\n",
    "            beta = beta, \n",
    "            sigma = sigma, \n",
    "            rewards = sampled_rewards, \n",
    "            features = agent.model.feature_map(actions, state_contexts, action_contexts), \n",
    "            idx = cur_step-1\n",
    "        )\n",
    "\n",
    "    #get evaluation contexts and true rewards \n",
    "    eval_contexts = env.sample_eval_contexts(access=True).to(device)\n",
    "    true_eval_rewards = env.get_true_rewards(eval_contexts, action_contexts)\n",
    "    \n",
    "    fantasy_rewards = agent.fantasize(beta, eval_contexts, action_contexts).to(device)\n",
    "    agent_actions = torch.argmax(fantasy_rewards.squeeze(), dim=1)\n",
    "\n",
    "    #calculate results from objective \n",
    "    results_dict = objective(\n",
    "        agent_actions = agent_actions, \n",
    "        true_rewards = true_eval_rewards.to(device)\n",
    "    )\n",
    "\n",
    "    cumul_regret = cumul_regret / n_days\n",
    "    results_dict['regret'] = objective.weights[0] * cumul_regret + objective.weights[1] * results_dict['regret']\n",
    "    \n",
    "    #append results \n",
    "    percent_arms_correct_list.append(results_dict['percent_arms_correct'])\n",
    "    regret_list.append(results_dict['regret'])\n",
    "\n",
    "    #print results \n",
    "    if i % 10 == 0:\n",
    "        \n",
    "        print(i, \"Regret: \", np.mean(regret_list))\n",
    "        print(\"Percent Arms Correct: \", np.mean(percent_arms_correct_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwenv-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
