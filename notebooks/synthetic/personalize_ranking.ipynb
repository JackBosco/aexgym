{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch \n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from aexgym.env import PersSyntheticEnv, RankingSyntheticEnv\n",
    "from aexgym.model import PersonalizedLinearModel, PersonalizedRankingModel\n",
    "from aexgym.agent import LinearTS, LinearUniform, LinearUCB, LinearRho, RankingUniform, RankingTS, RankingRho\n",
    "from aexgym.objectives import contextual_best_arm, contextual_simple_regret\n",
    "from scripts.setup_script import make_uniform_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "n_days = 5\n",
    "n_arms = 10\n",
    "context_len = 100\n",
    "n_steps = n_days \n",
    "batch_size = 100\n",
    "s2 = 0.1 * torch.ones((n_days, 1))\n",
    "\n",
    "n_items = 6\n",
    "total_items = 50\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personalization \n",
    "\n",
    "#initialize parameterss\n",
    "n_objs = 1\n",
    "scaling = 1 / (batch_size*100)\n",
    "pers_beta, pers_sigma = make_uniform_prior(context_len, scaling, n_objs=n_objs)\n",
    "user_context_mu, user_context_var = torch.ones(context_len), 0.5*torch.eye(context_len)\n",
    "item_context_mu, item_context_var = torch.ones(context_len), 0.5*torch.eye(context_len)\n",
    "\n",
    "\n",
    "#initialize synthetic and agent model \n",
    "model = PersonalizedRankingModel(\n",
    "    beta_0 = pers_beta, \n",
    "    sigma_0 = pers_sigma, \n",
    "    n_arms = n_arms, \n",
    "    s2 = s2,  \n",
    "    n_objs=n_objs\n",
    ")\n",
    "\n",
    "#initialize synthetic environment\n",
    "env = RankingSyntheticEnv(\n",
    "    true_env = model,\n",
    "    n_steps = n_steps,\n",
    "    user_context_mu = user_context_mu, \n",
    "    user_context_var = user_context_var,\n",
    "    item_context_mu = item_context_mu,\n",
    "    item_context_var = item_context_var, \n",
    "    context_len = context_len, \n",
    "    batch_size = batch_size,\n",
    "    n_arms = n_arms,\n",
    "    n_items = n_items,\n",
    "    total_items = total_items\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100]) torch.Size([100, 50, 100])\n",
      "6 torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "contexts, cur_step = env.reset()\n",
    "state_contexts, action_contexts, eval_contexts = contexts \n",
    "user_contexts, item_contexts = state_contexts\n",
    "n_items, ranking_contexts = action_contexts\n",
    "print(user_contexts.shape, item_contexts.shape)\n",
    "print(n_items, ranking_contexts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize agent  \n",
    "agent = RankingUniform(model, \"Linear Uniform\")\n",
    "#agent = RankingTS(model, \"Linear TS\", toptwo=False, n_samples = 1)\n",
    "#agent = RankingTS(model, \"Linear TS\", toptwo=True, n_samples = 100)\n",
    "#agent = RankingRho(model, \"Linear Rho\", lr=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Regret:  0.038807712495326996\n",
      "Percent Arms Correct:  0.66\n",
      "1 Regret:  0.04593134671449661\n",
      "Percent Arms Correct:  0.615\n",
      "2 Regret:  0.045784598837296166\n",
      "Percent Arms Correct:  0.61\n",
      "3 Regret:  0.04896984621882439\n",
      "Percent Arms Correct:  0.5800000000000001\n",
      "4 Regret:  0.0506954088807106\n",
      "Percent Arms Correct:  0.562\n",
      "5 Regret:  0.04813119644920031\n",
      "Percent Arms Correct:  0.5800000000000001\n",
      "6 Regret:  0.04655326743211065\n",
      "Percent Arms Correct:  0.5857142857142857\n",
      "7 Regret:  0.04586641909554601\n",
      "Percent Arms Correct:  0.6012500000000001\n",
      "8 Regret:  0.045859927104579076\n",
      "Percent Arms Correct:  0.6055555555555556\n",
      "9 Regret:  0.04438349362462759\n",
      "Percent Arms Correct:  0.608\n",
      "10 Regret:  0.04441931217231534\n",
      "Percent Arms Correct:  0.6072727272727273\n",
      "11 Regret:  0.04423101603363951\n",
      "Percent Arms Correct:  0.6075\n",
      "12 Regret:  0.04285366188448209\n",
      "Percent Arms Correct:  0.6146153846153847\n",
      "13 Regret:  0.042702760946537764\n",
      "Percent Arms Correct:  0.6157142857142858\n",
      "14 Regret:  0.04274266796807448\n",
      "Percent Arms Correct:  0.6186666666666667\n",
      "15 Regret:  0.041641328716650605\n",
      "Percent Arms Correct:  0.6231249999999999\n",
      "16 Regret:  0.0404095086542999\n",
      "Percent Arms Correct:  0.6317647058823529\n",
      "17 Regret:  0.03984609629131026\n",
      "Percent Arms Correct:  0.6344444444444444\n",
      "18 Regret:  0.03937010486659251\n",
      "Percent Arms Correct:  0.6342105263157894\n",
      "19 Regret:  0.040035405382514\n",
      "Percent Arms Correct:  0.6255\n",
      "20 Regret:  0.04052374440999258\n",
      "Percent Arms Correct:  0.6209523809523809\n",
      "21 Regret:  0.04100625708021901\n",
      "Percent Arms Correct:  0.6186363636363637\n",
      "22 Regret:  0.04108691992967025\n",
      "Percent Arms Correct:  0.6191304347826087\n",
      "23 Regret:  0.041106430192788444\n",
      "Percent Arms Correct:  0.6179166666666667\n",
      "24 Regret:  0.041540426164865495\n",
      "Percent Arms Correct:  0.6172\n",
      "25 Regret:  0.04223717992695478\n",
      "Percent Arms Correct:  0.615\n",
      "26 Regret:  0.041811897384899634\n",
      "Percent Arms Correct:  0.6144444444444445\n",
      "27 Regret:  0.04133364751136729\n",
      "Percent Arms Correct:  0.6178571428571429\n",
      "28 Regret:  0.0409527737647295\n",
      "Percent Arms Correct:  0.6210344827586207\n",
      "29 Regret:  0.040675870267053445\n",
      "Percent Arms Correct:  0.62\n",
      "30 Regret:  0.040717729577614416\n",
      "Percent Arms Correct:  0.6193548387096776\n",
      "31 Regret:  0.041330551786813885\n",
      "Percent Arms Correct:  0.6146875\n",
      "32 Regret:  0.04156474221610662\n",
      "Percent Arms Correct:  0.6121212121212122\n",
      "33 Regret:  0.04193845418665339\n",
      "Percent Arms Correct:  0.6088235294117648\n",
      "34 Regret:  0.0423042925872973\n",
      "Percent Arms Correct:  0.6082857142857143\n",
      "35 Regret:  0.04245519053397907\n",
      "Percent Arms Correct:  0.6080555555555557\n",
      "36 Regret:  0.042372939906813005\n",
      "Percent Arms Correct:  0.6086486486486488\n",
      "37 Regret:  0.0423570605190961\n",
      "Percent Arms Correct:  0.6089473684210528\n",
      "38 Regret:  0.04215641257663568\n",
      "Percent Arms Correct:  0.6102564102564104\n",
      "39 Regret:  0.04194048414938152\n",
      "Percent Arms Correct:  0.611\n",
      "40 Regret:  0.04182393917041581\n",
      "Percent Arms Correct:  0.612439024390244\n",
      "41 Regret:  0.041568136729654814\n",
      "Percent Arms Correct:  0.6145238095238096\n",
      "42 Regret:  0.04146668583501217\n",
      "Percent Arms Correct:  0.6158139534883722\n",
      "43 Regret:  0.041835875673727554\n",
      "Percent Arms Correct:  0.6140909090909091\n",
      "44 Regret:  0.042025730676121184\n",
      "Percent Arms Correct:  0.6126666666666668\n",
      "45 Regret:  0.04214767925441265\n",
      "Percent Arms Correct:  0.6121739130434783\n",
      "46 Regret:  0.0420337679221275\n",
      "Percent Arms Correct:  0.6119148936170213\n",
      "47 Regret:  0.04183917213231325\n",
      "Percent Arms Correct:  0.6135416666666667\n",
      "48 Regret:  0.04182189360869174\n",
      "Percent Arms Correct:  0.6128571428571428\n",
      "49 Regret:  0.042099495530128477\n",
      "Percent Arms Correct:  0.6117999999999999\n",
      "50 Regret:  0.04197194288466491\n",
      "Percent Arms Correct:  0.6123529411764705\n",
      "51 Regret:  0.04182562038588982\n",
      "Percent Arms Correct:  0.6144230769230768\n",
      "52 Regret:  0.04183220680592195\n",
      "Percent Arms Correct:  0.6147169811320754\n",
      "53 Regret:  0.04168422747817305\n",
      "Percent Arms Correct:  0.6146296296296296\n",
      "54 Regret:  0.04197536341168664\n",
      "Percent Arms Correct:  0.6138181818181818\n",
      "55 Regret:  0.04221023552651916\n",
      "Percent Arms Correct:  0.6119642857142856\n",
      "56 Regret:  0.042558474041390834\n",
      "Percent Arms Correct:  0.610877192982456\n",
      "57 Regret:  0.04280796056163722\n",
      "Percent Arms Correct:  0.609655172413793\n",
      "58 Regret:  0.043058287920588155\n",
      "Percent Arms Correct:  0.6091525423728812\n",
      "59 Regret:  0.04320356634755929\n",
      "Percent Arms Correct:  0.6069999999999998\n",
      "60 Regret:  0.043553155709485536\n",
      "Percent Arms Correct:  0.6065573770491801\n",
      "61 Regret:  0.04361962581113461\n",
      "Percent Arms Correct:  0.6056451612903223\n",
      "62 Regret:  0.04366498949035766\n",
      "Percent Arms Correct:  0.6046031746031744\n",
      "63 Regret:  0.043724132352508605\n",
      "Percent Arms Correct:  0.60453125\n",
      "64 Regret:  0.04367823394445273\n",
      "Percent Arms Correct:  0.6056923076923076\n",
      "65 Regret:  0.04354672862047499\n",
      "Percent Arms Correct:  0.6069696969696969\n",
      "66 Regret:  0.043929759079395836\n",
      "Percent Arms Correct:  0.604776119402985\n",
      "67 Regret:  0.04380332612816025\n",
      "Percent Arms Correct:  0.6045588235294117\n",
      "68 Regret:  0.04389281511522722\n",
      "Percent Arms Correct:  0.6044927536231884\n",
      "69 Regret:  0.0441756650273289\n",
      "Percent Arms Correct:  0.6028571428571429\n",
      "70 Regret:  0.044159679135806124\n",
      "Percent Arms Correct:  0.6042253521126761\n",
      "71 Regret:  0.04417090888859497\n",
      "Percent Arms Correct:  0.6043055555555555\n",
      "72 Regret:  0.04417189225962717\n",
      "Percent Arms Correct:  0.6045205479452054\n",
      "73 Regret:  0.044226929948136616\n",
      "Percent Arms Correct:  0.6037837837837837\n",
      "74 Regret:  0.044529089430967964\n",
      "Percent Arms Correct:  0.6030666666666665\n",
      "75 Regret:  0.04444166473848255\n",
      "Percent Arms Correct:  0.6034210526315789\n",
      "76 Regret:  0.044270514716188626\n",
      "Percent Arms Correct:  0.6035064935064934\n",
      "77 Regret:  0.04443037954087441\n",
      "Percent Arms Correct:  0.603076923076923\n",
      "78 Regret:  0.04438616519298735\n",
      "Percent Arms Correct:  0.6026582278481012\n",
      "79 Regret:  0.044273855118080976\n",
      "Percent Arms Correct:  0.6032500000000001\n",
      "80 Regret:  0.044154738202507114\n",
      "Percent Arms Correct:  0.6037037037037037\n",
      "81 Regret:  0.043995150296789846\n",
      "Percent Arms Correct:  0.6042682926829269\n",
      "82 Regret:  0.04406624534223453\n",
      "Percent Arms Correct:  0.6040963855421687\n",
      "83 Regret:  0.0441507004378807\n",
      "Percent Arms Correct:  0.6035714285714286\n",
      "84 Regret:  0.0440076895058155\n",
      "Percent Arms Correct:  0.6047058823529413\n",
      "85 Regret:  0.04401219978408758\n",
      "Percent Arms Correct:  0.6041860465116281\n",
      "86 Regret:  0.044246455247717344\n",
      "Percent Arms Correct:  0.6022988505747128\n",
      "87 Regret:  0.04422324214299971\n",
      "Percent Arms Correct:  0.6031818181818182\n",
      "88 Regret:  0.044293224769696764\n",
      "Percent Arms Correct:  0.6031460674157303\n",
      "89 Regret:  0.04451449964609411\n",
      "Percent Arms Correct:  0.602\n",
      "90 Regret:  0.04464979735868318\n",
      "Percent Arms Correct:  0.6016483516483516\n",
      "91 Regret:  0.04449222317856291\n",
      "Percent Arms Correct:  0.6022826086956521\n",
      "92 Regret:  0.04446269836156599\n",
      "Percent Arms Correct:  0.6020430107526881\n",
      "93 Regret:  0.044306334127929614\n",
      "Percent Arms Correct:  0.6024468085106383\n",
      "94 Regret:  0.04420318146677394\n",
      "Percent Arms Correct:  0.6029473684210526\n",
      "95 Regret:  0.044216529408004135\n",
      "Percent Arms Correct:  0.6027083333333333\n",
      "96 Regret:  0.044335075471665444\n",
      "Percent Arms Correct:  0.6020618556701031\n",
      "97 Regret:  0.04432660818328055\n",
      "Percent Arms Correct:  0.601326530612245\n",
      "98 Regret:  0.04438514049832869\n",
      "Percent Arms Correct:  0.6013131313131314\n",
      "99 Regret:  0.044316184911876916\n",
      "Percent Arms Correct:  0.6015\n",
      "100 Regret:  0.04438292111574423\n",
      "Percent Arms Correct:  0.6006930693069307\n",
      "101 Regret:  0.04435068651960761\n",
      "Percent Arms Correct:  0.6006862745098039\n",
      "102 Regret:  0.04425229926060126\n",
      "Percent Arms Correct:  0.6009708737864078\n",
      "103 Regret:  0.04413225825947638\n",
      "Percent Arms Correct:  0.6015384615384616\n",
      "104 Regret:  0.04427700431219169\n",
      "Percent Arms Correct:  0.6008571428571429\n",
      "105 Regret:  0.044139862851292455\n",
      "Percent Arms Correct:  0.6014150943396226\n",
      "106 Regret:  0.044250358470550206\n",
      "Percent Arms Correct:  0.6007476635514019\n",
      "107 Regret:  0.04433731905495127\n",
      "Percent Arms Correct:  0.6007407407407407\n",
      "108 Regret:  0.044282488405294376\n",
      "Percent Arms Correct:  0.6005504587155963\n",
      "109 Regret:  0.044268622808158395\n",
      "Percent Arms Correct:  0.6005454545454544\n",
      "110 Regret:  0.04441916685853455\n",
      "Percent Arms Correct:  0.6\n",
      "111 Regret:  0.04427170815012817\n",
      "Percent Arms Correct:  0.6009821428571429\n",
      "112 Regret:  0.044229506177052985\n",
      "Percent Arms Correct:  0.6007964601769912\n",
      "113 Regret:  0.044208665149645845\n",
      "Percent Arms Correct:  0.6006140350877193\n",
      "114 Regret:  0.04429868448363698\n",
      "Percent Arms Correct:  0.6000869565217392\n",
      "115 Regret:  0.044176062055189036\n",
      "Percent Arms Correct:  0.6002586206896553\n",
      "116 Regret:  0.0442351061436865\n",
      "Percent Arms Correct:  0.6003418803418804\n",
      "117 Regret:  0.04431251082885063\n",
      "Percent Arms Correct:  0.5996610169491526\n",
      "118 Regret:  0.04434407812331905\n",
      "Percent Arms Correct:  0.5996638655462185\n",
      "119 Regret:  0.04434394479418794\n",
      "Percent Arms Correct:  0.5995833333333332\n",
      "120 Regret:  0.04436327178369869\n",
      "Percent Arms Correct:  0.598677685950413\n",
      "121 Regret:  0.04445941810358743\n",
      "Percent Arms Correct:  0.59827868852459\n",
      "122 Regret:  0.044440731890802464\n",
      "Percent Arms Correct:  0.5983739837398372\n",
      "123 Regret:  0.044298079901284745\n",
      "Percent Arms Correct:  0.5992741935483868\n",
      "124 Regret:  0.04424287910759449\n",
      "Percent Arms Correct:  0.5991199999999998\n",
      "125 Regret:  0.04418176109532988\n",
      "Percent Arms Correct:  0.5993650793650791\n",
      "126 Regret:  0.04408267030389759\n",
      "Percent Arms Correct:  0.6000787401574801\n",
      "127 Regret:  0.044057562583475374\n",
      "Percent Arms Correct:  0.6003125\n",
      "128 Regret:  0.04409659658233787\n",
      "Percent Arms Correct:  0.5998449612403101\n",
      "129 Regret:  0.04395735556116471\n",
      "Percent Arms Correct:  0.6005384615384615\n",
      "130 Regret:  0.04393881906307381\n",
      "Percent Arms Correct:  0.600381679389313\n",
      "131 Regret:  0.04389562787996097\n",
      "Percent Arms Correct:  0.6001515151515151\n",
      "132 Regret:  0.04382712985003801\n",
      "Percent Arms Correct:  0.6003007518796992\n",
      "133 Regret:  0.04362177722322852\n",
      "Percent Arms Correct:  0.6012686567164178\n",
      "134 Regret:  0.04350440862278144\n",
      "Percent Arms Correct:  0.6022962962962963\n",
      "135 Regret:  0.04342391104985248\n",
      "Percent Arms Correct:  0.6025\n",
      "136 Regret:  0.04346285343007015\n",
      "Percent Arms Correct:  0.6024087591240876\n",
      "137 Regret:  0.04340828011703232\n",
      "Percent Arms Correct:  0.6026811594202899\n",
      "138 Regret:  0.04339390672850523\n",
      "Percent Arms Correct:  0.6029496402877698\n",
      "139 Regret:  0.04335496230050921\n",
      "Percent Arms Correct:  0.6027857142857143\n",
      "140 Regret:  0.043381386020399156\n",
      "Percent Arms Correct:  0.6026950354609929\n",
      "141 Regret:  0.04331897722530953\n",
      "Percent Arms Correct:  0.602605633802817\n",
      "142 Regret:  0.04336174685586166\n",
      "Percent Arms Correct:  0.6025174825174826\n",
      "143 Regret:  0.04332930782240712\n",
      "Percent Arms Correct:  0.6027083333333333\n",
      "144 Regret:  0.043433247981914155\n",
      "Percent Arms Correct:  0.6017241379310345\n",
      "145 Regret:  0.04350025761770467\n",
      "Percent Arms Correct:  0.6013698630136987\n",
      "146 Regret:  0.043480390404053285\n",
      "Percent Arms Correct:  0.600952380952381\n",
      "147 Regret:  0.043455905822181215\n",
      "Percent Arms Correct:  0.601081081081081\n",
      "148 Regret:  0.043635052885085145\n",
      "Percent Arms Correct:  0.6006711409395973\n",
      "149 Regret:  0.043582519628107545\n",
      "Percent Arms Correct:  0.6004\n",
      "150 Regret:  0.04361971108773292\n",
      "Percent Arms Correct:  0.6003973509933774\n",
      "151 Regret:  0.04362597952498809\n",
      "Percent Arms Correct:  0.6000657894736843\n",
      "152 Regret:  0.04367927830739349\n",
      "Percent Arms Correct:  0.5997385620915032\n",
      "153 Regret:  0.04364922810829692\n",
      "Percent Arms Correct:  0.5998051948051948\n",
      "154 Regret:  0.04362838615573222\n",
      "Percent Arms Correct:  0.5994193548387097\n",
      "155 Regret:  0.04361022582564216\n",
      "Percent Arms Correct:  0.6\n",
      "156 Regret:  0.04353444697038763\n",
      "Percent Arms Correct:  0.6003821656050955\n",
      "157 Regret:  0.043553717304728456\n",
      "Percent Arms Correct:  0.6000632911392404\n",
      "158 Regret:  0.04364098384742092\n",
      "Percent Arms Correct:  0.5996855345911949\n",
      "159 Regret:  0.04363046853104606\n",
      "Percent Arms Correct:  0.59975\n",
      "160 Regret:  0.04373367585426902\n",
      "Percent Arms Correct:  0.5995031055900621\n",
      "161 Regret:  0.04370203042793789\n",
      "Percent Arms Correct:  0.5994444444444446\n",
      "162 Regret:  0.04366020363486983\n",
      "Percent Arms Correct:  0.5995092024539878\n",
      "163 Regret:  0.043659982010267856\n",
      "Percent Arms Correct:  0.5989024390243903\n",
      "164 Regret:  0.04377277722638665\n",
      "Percent Arms Correct:  0.5986666666666668\n",
      "165 Regret:  0.04375478895717716\n",
      "Percent Arms Correct:  0.5988554216867471\n",
      "166 Regret:  0.043659606446584544\n",
      "Percent Arms Correct:  0.5997005988023953\n",
      "167 Regret:  0.04365129972852412\n",
      "Percent Arms Correct:  0.5998214285714286\n",
      "168 Regret:  0.043585001254046456\n",
      "Percent Arms Correct:  0.6002958579881656\n",
      "169 Regret:  0.04350670841248597\n",
      "Percent Arms Correct:  0.6004705882352942\n",
      "170 Regret:  0.043606661826546426\n",
      "Percent Arms Correct:  0.6000000000000001\n",
      "171 Regret:  0.04363897102776655\n",
      "Percent Arms Correct:  0.5999418604651163\n",
      "172 Regret:  0.04367728602421077\n",
      "Percent Arms Correct:  0.5997687861271678\n",
      "173 Regret:  0.04360953046158812\n",
      "Percent Arms Correct:  0.5998850574712644\n",
      "174 Regret:  0.04346578742776598\n",
      "Percent Arms Correct:  0.6006857142857143\n",
      "175 Regret:  0.043361485840498724\n",
      "Percent Arms Correct:  0.6011931818181818\n",
      "176 Regret:  0.04336261173636563\n",
      "Percent Arms Correct:  0.6015254237288136\n",
      "177 Regret:  0.0433440599485897\n",
      "Percent Arms Correct:  0.6014606741573034\n",
      "178 Regret:  0.043327993343912026\n",
      "Percent Arms Correct:  0.601340782122905\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):\n\u001b[1;32m     11\u001b[0m     cumul_regret \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 12\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#print(env.mean_matrix)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     all_contexts, cur_step \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/aexgym/aexgym/env/ranking_env.py:127\u001b[0m, in \u001b[0;36mRankingSyntheticEnv.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_env\u001b[38;5;241m.\u001b[39muse_precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_beta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mMultivariateNormal(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_env\u001b[38;5;241m.\u001b[39mbeta_0\u001b[38;5;241m.\u001b[39msqueeze(), precision_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_env\u001b[38;5;241m.\u001b[39msigma_0\u001b[38;5;241m.\u001b[39msqueeze())\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/aexgym/aexgym/env/base_env.py:163\u001b[0m, in \u001b[0;36mBaseContextualEnv.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03mResets the environment to the initial state. \u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mThis function must be called before using the step function. \u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 163\u001b[0m state_contexts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_state_contexts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m eval_contexts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_eval_contexts()\n\u001b[1;32m    165\u001b[0m action_contexts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_action_contexts()\n",
      "File \u001b[0;32m~/aexgym/aexgym/env/ranking_env.py:47\u001b[0m, in \u001b[0;36mRankingContextSampler.sample_state_contexts\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_state_contexts\u001b[39m(\u001b[38;5;28mself\u001b[39m, i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontexts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_contexts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontexts\n",
      "File \u001b[0;32m~/aexgym/aexgym/env/ranking_env.py:42\u001b[0m, in \u001b[0;36mRankingContextSampler.sample_contexts\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     40\u001b[0m user_contexts \u001b[38;5;241m=\u001b[39m user_mvn\u001b[38;5;241m.\u001b[39msample((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,)) \n\u001b[1;32m     41\u001b[0m item_mvn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mMultivariateNormal(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_context_mu, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_context_var)\n\u001b[0;32m---> 42\u001b[0m item_contexts \u001b[38;5;241m=\u001b[39m \u001b[43mitem_mvn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_items\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m contexts \u001b[38;5;241m=\u001b[39m (user_contexts, item_contexts)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m contexts\n",
      "File \u001b[0;32m~/.conda/envs/o3d/lib/python3.11/site-packages/torch/distributions/distribution.py:164\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mGenerates a sample_shape shaped sample or sample_shape shaped batch of\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03msamples if the distribution parameters are batched.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/o3d/lib/python3.11/site-packages/torch/distributions/multivariate_normal.py:241\u001b[0m, in \u001b[0;36mMultivariateNormal.rsample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrsample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mSize()):\n\u001b[1;32m    240\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended_shape(sample_shape)\n\u001b[0;32m--> 241\u001b[0m     eps \u001b[38;5;241m=\u001b[39m \u001b[43m_standard_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m+\u001b[39m _batch_mv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbroadcasted_scale_tril, eps)\n",
      "File \u001b[0;32m~/.conda/envs/o3d/lib/python3.11/site-packages/torch/distributions/utils.py:63\u001b[0m, in \u001b[0;36m_standard_normal\u001b[0;34m(shape, dtype, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# [JIT WORKAROUND] lack of support for .normal_()\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnormal(\n\u001b[1;32m     60\u001b[0m         torch\u001b[38;5;241m.\u001b[39mzeros(shape, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice),\n\u001b[1;32m     61\u001b[0m         torch\u001b[38;5;241m.\u001b[39mones(shape, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice),\n\u001b[1;32m     62\u001b[0m     )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_probs = False\n",
    "torch.manual_seed(0)\n",
    "objective = contextual_simple_regret()\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "regret_list = []\n",
    "percent_arms_correct_list = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10000):\n",
    "    cumul_regret = 0\n",
    "    env.reset()\n",
    "    #print(env.mean_matrix)\n",
    "    all_contexts, cur_step = env.reset()\n",
    "    beta, sigma = agent.model.reset()\n",
    "    #print(beta, sigma)\n",
    "    beta, sigma = beta.to(device), sigma.to(device)\n",
    "    while env.n_steps - cur_step > 0:\n",
    "\n",
    "        #move to device \n",
    "        state_contexts, action_contexts, eval_contexts = all_contexts \n",
    "        state_contexts = tuple(contexts.to(device) for contexts in state_contexts)\n",
    "        eval_contexts = tuple(contexts.to(device) for contexts in eval_contexts)\n",
    "        action_contexts = (action_contexts[0], action_contexts[1].to(device))\n",
    "        #train agent \n",
    "        agent.train_agent( \n",
    "            beta = beta, \n",
    "            sigma = sigma, \n",
    "            cur_step = cur_step, \n",
    "            n_steps = n_steps, \n",
    "            train_context_sampler = env.sample_train_contexts, \n",
    "            eval_contexts = eval_contexts,\n",
    "            eval_action_contexts = action_contexts, \n",
    "            real_batch = batch_size, \n",
    "            print_losses=False, \n",
    "            objective=objective,\n",
    "            repeats=10000\n",
    "        )   \n",
    "        #get probabilities\n",
    "        probs = agent(\n",
    "            beta = beta, \n",
    "            sigma = sigma, \n",
    "            contexts = state_contexts, \n",
    "            action_contexts = action_contexts, \n",
    "            objective = objective\n",
    "        ) \n",
    "     \n",
    "        #print probabilities \n",
    "        if print_probs == True:\n",
    "            print(agent.name, env.n_steps - cur_step, torch.mean(probs, dim=0))\n",
    "        \n",
    "        #get actions and move to new state\n",
    "        actions = torch.distributions.Categorical(probs).sample()\n",
    "        \n",
    "        #move to next environment state \n",
    "        all_contexts, sampled_rewards, sampled_features, cur_step  = env.step(\n",
    "            state_contexts = state_contexts, \n",
    "            action_contexts = action_contexts, \n",
    "            actions = actions\n",
    "        )\n",
    "\n",
    "\n",
    "        rewards = objective(\n",
    "            agent_actions = actions,\n",
    "            true_rewards = env.get_true_rewards(state_contexts, action_contexts)\n",
    "        )\n",
    "\n",
    "        cumul_regret += rewards['regret']\n",
    "        \n",
    "        #update model state \n",
    "        beta, sigma = agent.model.update_posterior(\n",
    "            beta = beta, \n",
    "            sigma = sigma, \n",
    "            rewards = sampled_rewards, \n",
    "            features = sampled_features, \n",
    "            idx = cur_step-1\n",
    "        )\n",
    "    #get evaluation contexts and true rewards \n",
    "    eval_contexts = env.sample_eval_contexts(access=True)\n",
    "    eval_contexts = tuple(contexts.to(device) for contexts in eval_contexts)\n",
    "    true_eval_rewards = env.get_true_rewards(eval_contexts, action_contexts)\n",
    "    fantasy_rewards = agent.fantasize(beta, eval_contexts, action_contexts).to(device)\n",
    "    agent_actions = torch.argmax(fantasy_rewards.squeeze(), dim=1)\n",
    "    #calculate results from objective\n",
    "    #fantasy_rewards = torch.randn(fantasy_rewards.shape) \n",
    "    results_dict = objective(\n",
    "        agent_actions = agent_actions, \n",
    "        true_rewards = true_eval_rewards.to(device)\n",
    "    )\n",
    "    \n",
    "    #append results \n",
    "    percent_arms_correct_list.append(results_dict['percent_arms_correct'])\n",
    "    regret_list.append(results_dict['regret'])\n",
    "\n",
    "    #print results \n",
    "    if i % 1 == 0:\n",
    "        \n",
    "        print(i, \"Regret: \", np.mean(regret_list))\n",
    "        print(\"Percent Arms Correct: \", np.mean(percent_arms_correct_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
