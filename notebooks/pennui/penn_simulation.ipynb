{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Download Instructions: \n",
    "\n",
    "Download zip file from https://www.upjohn.org/data-tools/employment-research-data-center/pennsylvania-reemployment-bonus-demonstration. \n",
    "\n",
    "After downloading zip file, turn the recsfile.dta file into a csv file, and put it under data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch \n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from aexgym.model import PersonalizedLinearModel\n",
    "from aexgym.agent import LinearTS, LinearUniform, LinearUCB\n",
    "from aexgym.objectives import contextual_best_arm, contextual_simple_regret\n",
    "from notebooks.pennui.penn_env import PennEnv\n",
    "from notebooks.pennui.process_penn import process_penn\n",
    "from scripts.setup_script import make_uniform_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/penn.csv\"\n",
    "df = process_penn(PATH, outcome=1, linear_impute=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "n_days = 6\n",
    "n_arms = 7\n",
    "context_len = 75\n",
    "n_steps = n_days \n",
    "batch_size = 100\n",
    "s2 = 0.1 * torch.ones((n_days, 1))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personalization \n",
    "\n",
    "#initialize MDPs\n",
    "n_objs = 1\n",
    "scaling = 1 / (batch_size*10)\n",
    "pers_beta, pers_sigma = make_uniform_prior(context_len*n_arms, scaling, n_objs=n_objs)\n",
    "\n",
    "model = PersonalizedLinearModel(\n",
    "    beta_0 = pers_beta, \n",
    "    sigma_0 = pers_sigma, \n",
    "    n_arms = n_arms, \n",
    "    s2 = s2, \n",
    "    n_objs = n_objs\n",
    ")\n",
    "env = PennEnv(df, batch_size, n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LinearUniform(model, \"Linear Uniform\")\n",
    "agent = LinearTS(model, \"Linear TS\", toptwo=False, n_samples = 1)\n",
    "#agent = LinearTS(model, \"Linear TS toptwo\", toptwo=True, n_samples = 100)\n",
    "#agent = LinearUCB(model, \"Linear UCB\", alpha = 0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regret:  2.276535749435425\n",
      "Percent Arms Correct:  0.19\n",
      "Regret:  2.7170725519006904\n",
      "Percent Arms Correct:  0.16818181818181818\n",
      "Regret:  2.8555057843526206\n",
      "Percent Arms Correct:  0.15476190476190477\n",
      "Regret:  2.8637644014050885\n",
      "Percent Arms Correct:  0.15129032258064515\n",
      "Regret:  2.8795377277746432\n",
      "Percent Arms Correct:  0.15317073170731707\n",
      "Regret:  2.8570394399119357\n",
      "Percent Arms Correct:  0.1523529411764706\n",
      "Regret:  2.847397071416261\n",
      "Percent Arms Correct:  0.15311475409836064\n",
      "Regret:  2.868101672387459\n",
      "Percent Arms Correct:  0.1529577464788732\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m batch \u001b[38;5;241m=\u001b[39m state_contexts\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#get probabilities\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m probs \u001b[38;5;241m=\u001b[39m agent(\n\u001b[1;32m     33\u001b[0m     beta \u001b[38;5;241m=\u001b[39m beta, \n\u001b[1;32m     34\u001b[0m     sigma \u001b[38;5;241m=\u001b[39m sigma, \n\u001b[1;32m     35\u001b[0m     contexts \u001b[38;5;241m=\u001b[39m state_contexts, \n\u001b[1;32m     36\u001b[0m     action_contexts \u001b[38;5;241m=\u001b[39m action_contexts, \n\u001b[1;32m     37\u001b[0m     objective \u001b[38;5;241m=\u001b[39m objective\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#print probabilities \u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m print_probs \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/aexgym/aexgym/agent/linear/linear_ts.py:36\u001b[0m, in \u001b[0;36mLinearTS.forward\u001b[0;34m(self, beta, sigma, contexts, action_contexts, objective, costs)\u001b[0m\n\u001b[1;32m     34\u001b[0m n_objs \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     35\u001b[0m betas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_betas(beta[:, i], sigma[:, :, i], batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_objs)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfeatures_all_arms(contexts, action_contexts)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#n = batch_size, k = n_arms, f = feature_dim\u001b[39;00m\n\u001b[1;32m     39\u001b[0m fake_mc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnkf,nsfd->nksd\u001b[39m\u001b[38;5;124m'\u001b[39m, features\u001b[38;5;241m.\u001b[39mfloat(), betas\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m~/repos/aexgym/aexgym/model/personalized_linear_model.py:55\u001b[0m, in \u001b[0;36mPersonalizedLinearModel.features_all_arms\u001b[0;34m(self, contexts, action_contexts)\u001b[0m\n\u001b[1;32m     53\u001b[0m arms_array \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(context_matrix, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m context_array \u001b[38;5;241m=\u001b[39m contexts\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_arms)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnk,njk->njk\u001b[39m\u001b[38;5;124m'\u001b[39m, context_array, arms_array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/functional.py:380\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39meinsum(equation, operands)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    382\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#set seed and experiment parameters \n",
    "torch.manual_seed(0)\n",
    "torch.set_printoptions(sci_mode=False) \n",
    "print_probs = False\n",
    "\n",
    "#set objective \n",
    "objective = contextual_simple_regret()\n",
    "\n",
    "#initialize lists\n",
    "regret_list = []\n",
    "percent_arms_correct_list = []\n",
    "\n",
    "#run experiment simulation\n",
    "for i in range(10000):\n",
    "    env.reset()\n",
    "    #print(env.mean_matrix)\n",
    "    all_contexts, cur_step = env.reset()\n",
    "    beta, sigma = agent.model.reset()\n",
    "    #print(beta, sigma)\n",
    "    beta, sigma = beta.to(device), sigma.to(device)\n",
    "    beta_0, sigma_0 = beta.clone(), sigma.clone()\n",
    "    \n",
    "    while env.n_steps - cur_step > 0:\n",
    "\n",
    "        #move to device \n",
    "        state_contexts, action_contexts, eval_contexts = tuple(contexts.to(device) for contexts in all_contexts)\n",
    "        \n",
    "        #get batch size \n",
    "        batch = state_contexts.shape[0]\n",
    "\n",
    "        #get probabilities\n",
    "        probs = agent(\n",
    "            beta = beta, \n",
    "            sigma = sigma, \n",
    "            contexts = state_contexts, \n",
    "            action_contexts = action_contexts, \n",
    "            objective = objective\n",
    "        )\n",
    "     \n",
    "        #print probabilities \n",
    "        if print_probs == True:\n",
    "            print(agent.name, env.n_steps - cur_step, torch.mean(probs, dim=0))\n",
    "        \n",
    "        #get actions and move to new state\n",
    "        actions = torch.distributions.Categorical(probs).sample()\n",
    "        \n",
    "        #move to next environment state \n",
    "        all_contexts, sampled_rewards, sampled_features, cur_step  = env.step(\n",
    "            state_contexts = state_contexts, \n",
    "            action_contexts = action_contexts, \n",
    "            actions = actions\n",
    "        )\n",
    "        \n",
    "        #update model state \n",
    "        beta, sigma = agent.model.update_posterior(\n",
    "            beta = beta_0, \n",
    "            sigma = sigma_0, \n",
    "            rewards = sampled_rewards, \n",
    "            features = agent.model.feature_map(actions, state_contexts, action_contexts), \n",
    "            idx = cur_step-1\n",
    "        )\n",
    "\n",
    "    #get evaluation contexts and true rewards \n",
    "    eval_contexts = env.sample_eval_contexts(access=True).to(device)\n",
    "    true_eval_rewards = env.get_true_rewards(eval_contexts, action_contexts)\n",
    "    \n",
    "    #calculate results from objective \n",
    "    results_dict = objective(\n",
    "        fantasy_rewards = agent.fantasize(beta, eval_contexts, action_contexts).to(device), \n",
    "        true_rewards = true_eval_rewards.to(device)\n",
    "    )\n",
    "    \n",
    "    #append results \n",
    "    percent_arms_correct_list.append(results_dict['percent_arms_correct'])\n",
    "    regret_list.append(results_dict['regret'])\n",
    "\n",
    "    #print results \n",
    "    if i % 10 == 0:\n",
    "        \n",
    "        print(\"Regret: \", np.mean(regret_list))\n",
    "        print(\"Percent Arms Correct: \", np.mean(percent_arms_correct_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
